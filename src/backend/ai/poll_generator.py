"""
AI Poll Generator Service

Uses Microsoft Foundry (formerly Azure AI Foundry) with Agent Framework
to generate unbiased poll questions from current events.
"""

from datetime import datetime, timedelta, timezone
from typing import TYPE_CHECKING, Any, Optional
from uuid import uuid4

import structlog
from pydantic import BaseModel

from ai.event_aggregator import NewsEvent
from core.config import settings
from schemas.poll import Poll, PollChoice

if TYPE_CHECKING:
    from azure.ai.projects.aio import AIProjectClient
    from azure.identity.aio import DefaultAzureCredential
    from openai import AsyncAzureOpenAI

logger = structlog.get_logger(__name__)


class GeneratedPoll(BaseModel):
    """A poll generated by the AI system."""

    question: str
    choices: list[str]
    category: str
    source_event_id: str
    bias_check_passed: bool
    bias_analysis: dict
    suggested_duration_hours: int


class PollGenerator:
    """
    AI-powered poll generator using Microsoft Agent Framework.

    Generates unbiased poll questions from current events by:
    1. Analyzing multiple perspectives on an event
    2. Generating neutral question framing
    3. Creating balanced answer choices
    4. Performing bias detection and correction

    Uses the Agent Framework with Microsoft Foundry for
    production-grade AI capabilities.
    """

    SYSTEM_PROMPT = """You are an expert pollster and political scientist tasked with
creating unbiased, fair poll questions from current events. Your goals are:

1. NEUTRALITY: Questions must not favor any political party, ideology, or outcome
2. CLARITY: Questions must be clear and unambiguous
3. BALANCE: Answer choices must represent all major viewpoints fairly
4. INCLUSIVITY: Include "Undecided" or "Other" options when appropriate
5. NON-LEADING: Avoid loaded language or presuppositions

When generating polls:
- Frame questions objectively without emotional language
- Present all sides of an issue fairly
- Avoid false dichotomies - include nuanced options
- Don't assume the reader's position
- Use neutral, professional language

Output format:
{
    "question": "The poll question",
    "choices": ["Choice 1", "Choice 2", "Choice 3", ...],
    "category": "Category name",
    "bias_analysis": {
        "potential_issues": [],
        "mitigations_applied": [],
        "confidence_score": 0.95
    }
}"""

    def __init__(self) -> None:
        self._agent: Any = None
        self._initialized: bool = False
        self._client: Optional["AIProjectClient"] = None
        self._openai_client: Optional["AsyncAzureOpenAI"] = None
        self._credential: Optional["DefaultAzureCredential"] = None

    async def initialize(self) -> None:
        """Initialize the AI agent for poll generation."""
        if self._initialized:
            return

        # Try Azure AI Foundry first, then fall back to direct Azure OpenAI
        if settings.FOUNDRY_PROJECT_ENDPOINT:
            try:
                # Import Azure AI Projects SDK components
                from azure.ai.projects.aio import AIProjectClient
                from azure.identity.aio import DefaultAzureCredential

                self._credential = DefaultAzureCredential()
                self._client = AIProjectClient(
                    endpoint=settings.FOUNDRY_PROJECT_ENDPOINT,
                    credential=self._credential,
                )

                # Get OpenAI client for chat completions
                self._openai_client = await self._client.get_openai_client()

                self._initialized = True
                logger.info("Poll generator initialized with Azure AI Foundry")
                return

            except ImportError:
                logger.warning("Azure AI Projects not installed, trying direct Azure OpenAI")
            except Exception as e:
                logger.warning(f"Failed to initialize Foundry client: {e}, trying direct Azure OpenAI")

        # Fall back to direct Azure OpenAI
        if settings.AZURE_OPENAI_ENDPOINT and settings.AZURE_OPENAI_API_KEY:
            try:
                from openai import AsyncAzureOpenAI

                self._openai_client = AsyncAzureOpenAI(
                    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
                    api_key=settings.AZURE_OPENAI_API_KEY,
                    api_version="2024-02-15-preview",
                )
                self._initialized = True
                logger.info("Poll generator initialized with direct Azure OpenAI")
                return

            except ImportError:
                logger.warning("openai package not installed")
            except Exception as e:
                logger.error(f"Failed to initialize Azure OpenAI client: {e}")

        logger.warning("No AI endpoint configured, using mock mode")
        self._initialized = True

    async def generate_poll_from_event(
        self,
        event: NewsEvent,
        context: dict | None = None,
    ) -> GeneratedPoll | None:
        """
        Generate an unbiased poll question from a news event.

        Args:
            event: The news event to generate a poll from
            context: Additional context including diverse perspectives

        Returns:
            A generated poll or None if generation failed
        """
        await self.initialize()

        # Build the prompt
        prompt = f"""Generate an unbiased poll question based on this news event:

HEADLINE: {event.title}

SUMMARY: {event.summary}

CATEGORY: {event.category}

KEYWORDS: {", ".join(event.keywords)}

{f"ADDITIONAL CONTEXT: {context}" if context else ""}

Create a poll that:
1. Captures the key question the public might have about this event
2. Offers balanced answer choices representing different viewpoints
3. Uses neutral, non-leading language
4. Includes 3-5 answer choices

Return your response as JSON."""

        try:
            # For development or when AI is not configured, use mock data
            if not self._openai_client:
                return self._generate_mock_poll(event)

            # Use OpenAI client for chat completions
            model = settings.AZURE_OPENAI_DEPLOYMENT or settings.FOUNDRY_MODEL_DEPLOYMENT or "gpt-4o-mini"
            response = await self._openai_client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
            )

            # Parse response
            import json

            content = response.choices[0].message.content
            if not content:
                logger.warning("Empty response from AI, using mock")
                return self._generate_mock_poll(event)

            result = json.loads(content)

            return GeneratedPoll(
                question=result["question"],
                choices=result["choices"],
                category=event.category,
                source_event_id=event.id,
                bias_check_passed=result.get("bias_analysis", {}).get("confidence_score", 0) > 0.8,
                bias_analysis=result.get("bias_analysis", {}),
                suggested_duration_hours=24,
            )

        except Exception as e:
            logger.error(f"Failed to generate poll: {e}")
            return None

    def _generate_mock_poll(self, event: NewsEvent) -> GeneratedPoll:
        """Generate a mock poll for development/testing."""
        mock_questions: dict[str, dict[str, str | list[str]]] = {
            "Environment": {
                "question": "Regarding recent climate discussions, what approach do you think governments should prioritize?",
                "choices": [
                    "Aggressive emissions targets with economic trade-offs",
                    "Gradual transition balancing economy and environment",
                    "Market-based solutions without government mandates",
                    "Focus on adaptation rather than prevention",
                    "Undecided / Need more information",
                ],
            },
            "Technology": {
                "question": "How should AI technology be regulated?",
                "choices": [
                    "Strict government oversight and licensing",
                    "Industry self-regulation with guidelines",
                    "Minimal regulation to encourage innovation",
                    "International coordination on standards",
                    "Undecided / Need more information",
                ],
            },
        }

        default: dict[str, str | list[str]] = {
            "question": f"What is your view on: {event.title}?",
            "choices": [
                "Strongly support the described approach",
                "Somewhat support with reservations",
                "Neutral / Mixed feelings",
                "Somewhat oppose",
                "Strongly oppose",
            ],
        }

        poll_template = mock_questions.get(event.category, default)

        # Cast to expected types since we know the dict structure
        question = str(poll_template["question"])
        choices = list(poll_template["choices"]) if isinstance(poll_template["choices"], list) else []

        return GeneratedPoll(
            question=question,
            choices=choices,
            category=event.category,
            source_event_id=event.id,
            bias_check_passed=True,
            bias_analysis={
                "potential_issues": [],
                "mitigations_applied": ["neutral framing", "balanced options"],
                "confidence_score": 0.92,
            },
            suggested_duration_hours=24,
        )

    BIAS_VALIDATION_PROMPT = """You are an expert in detecting bias in poll questions.
Analyze the following poll for any potential bias issues:

QUESTION: {question}

CHOICES:
{choices}

CATEGORY: {category}

Check for:
1. LEADING QUESTIONS: Does the question push toward a particular answer?
2. LOADED LANGUAGE: Does the question use emotionally charged words?
3. FALSE DICHOTOMY: Are nuanced positions missing from the choices?
4. UNBALANCED OPTIONS: Do choices favor one side over another?
5. MISSING PERSPECTIVES: Are major viewpoints unrepresented?
6. PRESUPPOSITIONS: Does the question assume facts not established?

Respond in JSON format:
{{
    "passed": true/false,
    "issues": ["List of specific issues found"],
    "suggestions": ["Specific suggestions for improvement"],
    "confidence": 0.0-1.0
}}"""

    async def validate_poll_bias(
        self,
        poll: GeneratedPoll,
    ) -> dict:
        """
        Validate a poll for potential bias issues.

        Uses a separate AI evaluation to check for:
        - Leading questions
        - Unbalanced answer choices
        - Loaded language
        - Missing perspectives
        """
        await self.initialize()

        # Use AI to validate if available
        if self._openai_client:
            try:
                import json

                choices_text = "\n".join(f"- {c}" for c in poll.choices)
                prompt = self.BIAS_VALIDATION_PROMPT.format(
                    question=poll.question,
                    choices=choices_text,
                    category=poll.category,
                )

                response = await self._openai_client.chat.completions.create(
                    model=settings.FOUNDRY_MODEL_DEPLOYMENT,
                    messages=[
                        {
                            "role": "system",
                            "content": "You are a bias detection expert. Respond only with valid JSON.",
                        },
                        {"role": "user", "content": prompt},
                    ],
                    temperature=0.3,  # Lower temperature for more consistent analysis
                    max_tokens=500,
                )

                result_text = response.choices[0].message.content
                # Extract JSON from response
                if "```json" in result_text:
                    result_text = result_text.split("```json")[1].split("```")[0]
                elif "```" in result_text:
                    result_text = result_text.split("```")[1].split("```")[0]

                result = json.loads(result_text.strip())

                passed = result.get("passed", True)
                issues_count = len(result.get("issues", []))
                logger.info(
                    f"Bias validation completed for '{poll.question[:50]}': passed={passed}, issues={issues_count}"
                )

                return result

            except Exception as e:
                logger.error(f"Bias validation failed: {e}")

        # Fallback: basic heuristic checks
        return self._heuristic_bias_check(poll)

    def _heuristic_bias_check(self, poll: GeneratedPoll) -> dict:
        """
        Fallback heuristic bias checking when AI is unavailable.

        Checks for common bias indicators without AI.
        """
        issues = []
        suggestions = []

        # Check for loaded language
        loaded_words = [
            "always",
            "never",
            "must",
            "should",
            "obviously",
            "clearly",
            "everyone knows",
            "radical",
            "extreme",
            "dangerous",
            "crisis",
            "disaster",
            "freedom",
            "liberty",
        ]
        question_lower = poll.question.lower()
        for word in loaded_words:
            if word in question_lower:
                issues.append(f"Potentially loaded language: '{word}'")
                suggestions.append(f"Consider rephrasing to remove '{word}'")

        # Check for yes/no binary (often too simplistic)
        choices_lower = [c.lower() for c in poll.choices]
        if len(poll.choices) == 2 and set(choices_lower) == {"yes", "no"}:
            issues.append("Binary yes/no options may oversimplify the issue")
            suggestions.append("Consider adding nuanced options like 'It depends' or 'Partially'")

        # Check for "undecided" option
        has_undecided = any(
            "undecided" in c.lower() or "unsure" in c.lower() or "other" in c.lower() for c in poll.choices
        )
        if not has_undecided and len(poll.choices) < 5:
            suggestions.append("Consider adding an 'Undecided/Other' option")

        # Check for balanced choice count
        if len(poll.choices) < 3:
            issues.append("Too few choices may not represent all viewpoints")
            suggestions.append("Add more nuanced options")

        passed = len(issues) == 0
        confidence = 0.7 if passed else 0.5  # Lower confidence for heuristic check

        return {
            "passed": passed,
            "issues": issues,
            "suggestions": suggestions,
            "confidence": confidence,
        }

    async def generate_daily_polls(
        self,
        events: list[NewsEvent],
        count: int = 5,
    ) -> list[Poll]:
        """
        Generate the daily set of featured polls.

        Selects diverse events across categories and generates
        unbiased poll questions for each.
        """
        generated_polls = []

        # Ensure category diversity
        categories_used: set[str] = set()
        events_to_use: list[NewsEvent] = []

        for event in sorted(events, key=lambda e: e.relevance_score, reverse=True):
            if event.category not in categories_used and len(events_to_use) < count:
                events_to_use.append(event)
                categories_used.add(event.category)

        # Fill remaining slots if needed
        for event in events:
            if event not in events_to_use and len(events_to_use) < count:
                events_to_use.append(event)

        # Generate polls
        for event in events_to_use:
            generated = await self.generate_poll_from_event(event)
            if generated and generated.bias_check_passed:
                poll = Poll(
                    id=str(uuid4()),
                    question=generated.question,
                    choices=[PollChoice(id=str(i), text=choice, order=i) for i, choice in enumerate(generated.choices)],
                    category=generated.category,
                    source_event=event.title,
                    created_at=datetime.now(timezone.utc),
                    expires_at=datetime.now(timezone.utc) + timedelta(hours=generated.suggested_duration_hours),
                    is_active=True,
                    ai_generated=True,
                    time_remaining_seconds=generated.suggested_duration_hours * 3600,
                )
                generated_polls.append(poll)

        return generated_polls
